# -*- coding: utf-8 -*-
"""Mentor Program - baseline subset

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y3N8tFJlc-RAK3pZVVIR7nZ2SVpHEsR2

Install deps
"""

!pip -q install datasets transformers sentencepiece accelerate scikit-learn pandas numpy matplotlib

"""Imports + seed"""

import random
import numpy as np
import pandas as pd

from datasets import load_dataset, Dataset
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay

import matplotlib.pyplot as plt

SEED = 42
random.seed(SEED)
np.random.seed(SEED)

"""Download dataset + prepare label mapping"""

from google.colab import files
import pandas as pd

uploaded = files.upload()

for fn in uploaded.keys():
    print(f'User uploaded file "{fn}" with length {len(uploaded[fn])} bytes')

# Assuming the uploaded file is named 'bbc_data.csv'
df = pd.read_csv('bbc_data.csv')

# Now that the df is loaded, we can continue with the rest of the notebook.
# I will replace the original problematic line of code with the new df.
# The 'ds' creation can be moved to a separate cell after the df is loaded.

"""After the file is uploaded and the DataFrame `df` is created, you can then proceed to create the `Dataset` object."""

from datasets import Dataset
from sklearn.model_selection import train_test_split

# Split the dataframe into training and testing sets
# We need to stratify by 'labels' to ensure class distribution is maintained
train_df, test_df = train_test_split(
    df,
    test_size=0.2, # Using a common 80/20 train-test split, can be adjusted
    stratify=df["labels"],
    random_state=SEED
)

ds = {
    "train": Dataset.from_pandas(train_df),
    "test": Dataset.from_pandas(test_df)
}

print("Train Dataset:")
print(ds["train"])
print("\nTest Dataset:")
print(ds["test"])

# Define label_names here, after df is loaded and before the prompt template is used
label_names = sorted(list(df['labels'].unique()))
print(f"\nDetected Labels: {label_names}")

"""Take a small evaluation subset (fast)"""

from sklearn.model_selection import train_test_split

N = 300  # total samples you want for the small evaluation subset

df_test = ds["test"].to_pandas()

# stratified sampling
df_small, _ = train_test_split(
    df_test,
    train_size=N,
    stratify=df_test["labels"], # Corrected: use 'labels' instead of 'label'
    random_state=SEED
)

test_small = ds["test"].select(df_small.index.tolist())

# sanity check
pd.Series(test_small["labels"]).value_counts().sort_index()

"""Load a local “LLM-ish” instruction model (CPU-friendly)"""

from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

MODEL_ID = "google/flan-t5-base"  # good tradeoff for CPU use
tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)
model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_ID)

"""Prompt template + classifier"""

LABEL_SET = ", ".join(label_names)

def build_prompt(text: str) -> str:
    # Instruction prompt: ask model to output ONLY one label from the set
    return (
        "You are a text classification assistant.\n"
        f"Task: Classify the news article into exactly one of these labels: {LABEL_SET}.\n"
        "Return only the label name and nothing else.\n\n"
        f"Article:\n{text}\n\n"
        "Label:"
    )

def normalize_prediction(pred: str) -> str:
    # Make parsing robust: strip, remove punctuation-ish, match to known labels
    pred_clean = pred.strip().replace('"', '').replace("'", "")
    pred_clean_lower = pred_clean.lower()

    # Exact match (case-insensitive)
    for lab in label_names:
        if pred_clean_lower == lab.lower():
            return lab

    # If model outputs extra words, pick best label by substring match
    for lab in label_names:
        if lab.lower() in pred_clean_lower:
            return lab

    # Fallback: "unknown" (won't crash metrics if you handle it)
    return "UNKNOWN"

def classify_with_flan_t5(text: str, max_new_tokens: int = 6) -> str:
    prompt = build_prompt(text)
    inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=512)
    outputs = model.generate(
        **inputs,
        max_new_tokens=max_new_tokens,
        do_sample=False,          # deterministic
        num_beams=1
    )
    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)
    return normalize_prediction(decoded)

"""Run inference on the subset"""

y_true = []
y_pred = []

for ex in test_small:
    true_label = ex["labels"]
    pred_label = classify_with_flan_t5(ex["data"])

    y_true.append(true_label)
    y_pred.append(pred_label)

pd.DataFrame({"true": y_true[:10], "pred": y_pred[:10]})

"""Metrics: precision/recall/F1 + confusion matrix"""

# Handle UNKNOWNs explicitly: keep them, but they will affect scores.
# If you prefer, you can map UNKNOWN -> a default label, but that's usually dishonest.
print(classification_report(y_true, y_pred, labels=label_names, digits=3, zero_division=0))

cm = confusion_matrix(y_true, y_pred, labels=label_names)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_names)

plt.figure(figsize=(6, 6))
disp.plot(values_format="d")
plt.xticks(rotation=45, ha="right")
plt.title("Confusion Matrix (Prompt → LLM Classifier)")
plt.show()

"""Quick error inspection (helpful for your notebook narrative)"""

rows = []
for ex, t, p in zip(test_small, y_true, y_pred):
    if t != p:
        rows.append({"true": t, "pred": p, "text": ex["data"][:300] + "..."})

pd.DataFrame(rows).head(20)
